---
layout: post
title: "파이콘(PyCon) 2019 세션 정리"
subtitle: "파이콘(PyCon) 2019 후기"
categories: etc
tags: lecture
comments: true
---

- 파이콘 2019에서 세션을 들으며 메모한 글입니다

---

### 파이썬과 커뮤니티와 한국어 오픈데이터
- 박은정님 키노트
- 프로그래밍은 왜 하는가?
- 취미 
- 먹고사니즘
- 개인의 성장
- **나의 커뮤니티에 기여하기 위해**
- 팀포퐁
	- 2011년 
	- 문제 의식 : 누구를 뽑을 것인가?
	- 발견한 문제점
		- 1) 객관적 자료 부족
		- 2) 뽑은 국회의원을 잊고 지냄
		- 국회정보 시스템에 정보는 다 있지만.. 어렵고 재미없음
		- 어떤 일을 하는지, 누가 누군지 모르겠고.. 접근성 떨어지는 문서
		- 검색 엔진이 접근할 수 없는 정책
		- 국민 모두가 접근할 수 있어야 하지 않을까?
	- 팀포퐁은 정치적 중립성, 자동화, 개방성의 가치를 가지고 결정이 됨
		- 기술로 대한민국 정치를 뒤흔들자
		- 직접 서비스를 만들며 성장하자
		- 프로토타입, 의원 네트워크 분석 등
	- 대한민국 정치의 모든 것이란 웹서비스가 생김
		- 타임라인을 위해 D3
		- NLP
		- PDF parsing
		- 선거구 시각화를 위해 지도 데이터도 만듬
			- 메르카토르 같은 투영법도 배움
		- 국회의원/의안 데이터 REST API => 데이터를 퍼블릭에 공개  
	- 좋은 개발 문화
		- 문서화 : 팀 내외와 소통하는 방ㅇ법
		- Git의 좋은 프랙티스 : 매너있게 소통
		- 새 프로젝트에 새 도구 도입
		- 탁상공론을 벗어나 working prototype으로 보여주기
	- 느낀점
		- 나와 내 주변을 바꿈 => 결국 세상을 바꾸게 되지 않을까
		- 시간이 좀 걸려도 괜찮다. 모르는 건 배우면 된다
		- 데이터를 가공해 오픈 데이터로 내놓는 것도 의미가 있다
- KoNLPy
	- 한국어 분석을 편리하게 하기 위해 시작
	- 오픈 소스는 있나? 성능은 어떻게 다르지?
	- 처음부터 커뮤니티 기여하겠단 생각은 아니었음
	- 파이콘이 한국에서 처음 열린대! => 잘 패키징해서 공개!
	- 사람들은 왜 KoNLPy를 사용했을까?
		- 초보자 : 사용법이 쉬워서?
		- 학생 : 보고 따라할 예시가 있어서?
		- 실무자 : 다양한 구현체 간 성능 비교가 편해서?
		- 외국인 : 문서가 영어로 쓰여 있어서?
		- 환경적 요인 : 이 당시 파이썬이 한창 인기몰이
	- 내가 필요한 도구는 내가 만들어 공유한다
		- 생각지도 못한 도움을 주고 받을 수 있고, 가치있는 일이다
	- 두번째 PyCon KR
		- representation learning이 굉장히 핫해짐
		- word2vec, doc2vec을 파이썬 커뮤니티에 소개해볼까?
		- KoNLPy를 공개했지만 토이데이터가 별로 없다
			- nsmc라는 한국어 영화평 데이터
			- 주어진 영화평을 긍정 또는 부정으로 분류하는 데이터셋
			- IMDB 데이터를 벤치마크
		- 내가 가진 기술이 대단하지 않아도 커뮤니티에 기여할 수 있다!
- 한국어 오픈 데이터
	- 꼭 하고 싶었던 이야기
		- 알파벳은 영어가 아니다 
		- 한글은 한국어가 아니다!
		- 한글은 문자, 한국어가 언어
		- 한국어 NLP, Korean NLP
		- 용어 정의를 명확히
	- 한국어 오픈데이터
		- 생각보다 굉장히 많음
	- 좋은 사례 1: KorQUAD
		- QnA 데이터셋
		- 충분한 양의 데이터 공개
		- 리더보드까지 공유
		- 라이센스 부분은 공유되지 않음
	- 좋은 사례 2: KSS
		- Single Speark Speech Dataset
		- 박규병님
		- 국내 최초의 음성 오픈 데이터
		- 제법 많은 분량
		- 라이센스가 뚜렷하게 명시되어 있어서 무엇을 할 수 있고 없는지가 명확함
	- 왜 오픈 데이터가 중요한가요?
		- 1) 벤치마크가 될 수 있음
			- 머신러닝 모델들은 데이터와 지표가 같아야 모델간 서로 비교 가능
			- 비교가 가능해지면 기술 발전이 옴
		- 2) 누구나 바로 분석이나 모델링을 시작할 수 있음
			- 프로그래밍에서 reinventing the wheel이 경계의 대상이 되듯 모두가 데이터 취득과 정제를 할 필요는 없음
	- 데이터를 공개할 때 확인하면 좋은 점
		- 사용자가 바로 다운로드해서 사용할 수 있는가?
		- 원문에 갱인정보/저작권 문제는 없는가?
			- 오픈데이터는 기술 발전을 위해 매우 중요하지만 개인정보와 저작권도 존중받고 지켜져야 함
		- 가급적이면 라이센스를 꼭 명시
	- 오픈 데이터를 사용할 때 확인하면 좋은 점
		- 데이터가 충분히 큰가? 
		- 라이센스가 무엇인가?
			- 재배포가 가능한가?
			- 상업용으로 이용해도 되는가?
- 한국어 같이! 공유 :)


---

### 파이썬으로 구현하는 최적화 알고리즘
- 차지원님 
- [발표 자료](https://www.slideshare.net/JiwonCha3/pyconkr-2019-164422872)
- [Github](https://github.com/ryuncha/python_lpqp_optimization_tutorial)
- 에너지 스타트업 개발자로 취업하며 적응할 때 어려움이 있었음
- 백그라운드
	- 넓고 넓은 최적화의 세계
		- 수학적 계획법/최적화 기법
		- 최신/비전통 최적화 기법
		- 확률론적 과정 기법
		- 통계적 방법  
- 최적화 문제 구성
	- 목적 함수
	- 제약 함수
	- 변수
	- 계수
	- 상수
- 변수, 목적 함수, 제약조건에 따라 문제 유형이 다름
- 최적화 유형의 난이도 랭킹
	- LP : 선형 계획법
		- 목적함수, 제약함수가 모두 1차식이고 결정변수가 모두 실수 
		- 현실 문제는 비선형
	- NLP : 비선형 계획법
		- 목적함수, 제약함수 중 비선형 표현. n차
		- 이건 오픈소스가 거의 없음
		- 오래 걸림
- 모델링 라이브러리
	- 유저 - 솔버의 통역사
- 솔버
	- 연산 엔진
	- 솔버 성능에 따라 최적 결과값이 다름
- 기술적 해결법으로 문제 유형을 변겅하는게 좋음
- 모델링 라이브러리의 역할
	- 상황에 맞는 솔버 선택 가능
	- 쿼드라틱을 잘 푸는 솔버는 이거 등
- 모델링 구현 방법
	- Matrix form (CVXOPT, lv_solve, scipy.solve)
		- 계수를 뽑아서 c로, x로
		- 쿼드라틱은 더 복잡해짐
	- Symbolic form  
		- PuLP
		- 좀 더 직관적으로 표현
		- 에러가 나면 어떤 제약식에서 나왔는지 말해줌
		- 하지만 대부분 오픈소스 라이브러리가 LP만 지원.. symbolic은 거의 없음
		- cvxpy
		- 수식 표현방법이 다름
		- 정리된 목적함수가 작으면 심볼릭, 크면 매트릭스
- Matrix
	- 효율적 메모리 관리
	- 다양한 개발환경
- Symbolic
	- 유지보수의 편리성
	- 낮은 개발 난이도 
- 상황 1) 상업용 솔버를 사용하면
	- 해당 인터페이스 자체 모델링 라이브러리 사용
- 상황 2) 오픈소스
	- 잘 모르겠다면 CVXPY 추천
- 솔버 선택 팁
	- 사용 용도에 따른 SW 라이센스 문제
	- 성능, 연산 신뢰성 문제
	- 내 최적화 문제 유형을 지원하는지 : LP, MILP, QP, NLP 등
- SW 라이센스 종류
	- GNU GPL 
		- 사용하면 코드 공개해야함
	- GNU LGPL
		- 소스코드 공개 안해도 됨      
- 실사용 리뷰
	- GLPK : GNU라 기업에서 쓰기엔 좀..
	- CLP/CBC
	- OSQP인 ADMM 기법을 쓴다면 이걸 사용하는게 좋음!
- 예산의 제한이 없으면 CLPEX
	- Industry Standard로 압도적 속도 및 성능 
- 대학생이라면 Gurobi
	- 아카데믹 지원이 됨
	- 미래를 길게 보면 구로비가 안좋을수도..
- 스타트업이라면
	- 외부 배포할 일이 없고 LP만 풀면 GLPK
	- 성능만 기똥찬 CLP/CBC
	- OSQP   
- 최적화 모델 구현
	- 전력시장을 예시
	- 전력은 발전과 소비가 늘 동시에 
	- 전체의 총 수요와 발전을 잘 매치해야함
	- 언밸런스라면 주파수가 안맞아서 큰일날 수 있음
	- 각 발전기 최적 발전량 결정
		- 3개의 발전기의 발전량 스케쥴링
		- 조건 1 : 발전기 설비 상황
		- 조건 2 : 수급 균형(발전량=수요량)
	- 목적 함수 : 비용 최소화
		- 발전단가 최소화
	- 제약 조건
		- 최소 용량 <= 발전량 <= 최대 용량
		- 총 발전량 = 전력수요 
	- 변수가 너무 많아 일일히 하기 어렵
	- CVXPY와 numpy 호환이 좋음
	- 문제가 더 복잡하고 커질수록 솔버마다 차이가 커짐
- 심화 예제 : 하지만 현실은 QP
	- 사실 발전비용은 2차곡선
	- 목적함수 변경 (QP)
		- 제곱식을 추가
	- 수십만개의 변수, 수많은 비선형 제약조건
	- 발전기를 켤지/끌지도 결정해야 (IP)
	- 선로제약, 전압안정도 고려해야함 (NLP) 
- 참고 자료
	- [Comparison of Open-Source Linear
Programming Solvers](https://prod-ng.sandia.gov/techlib-noauth/access-control.cgi/2013/138847.pdf) : 62페이지
	- [A comparative analysis of optimization solvers](https://www.mat.univie.ac.at/~neum/ms/comparison.pdf) 
- 최적화에 대해 이미 알고있어서 꽤 아는 내용이었음. 그래도 오픈소스를 한번 싹 정리해주셔서 매우 좋았음!

---

### 뚱뚱하고 굼뜬 판다(Pandas)를 위한 효과적인 다이어트 전략
- 오성우님
- [발표 자료](https://drive.google.com/file/d/12faqaslFIF-Sg_sU3jeGyauW5ClRqS8D/view)
- Pandas는 관계형 데이터를 빠르고 유연하게 개발됨
- 흔히 맞닥뜨리는 문제
	- 데이터를 읽지도 못하고
	- 시간도 오래 걸리고
	- 작성하는 코드 방식도 제각각
- 원인
	- Pandas Memory mapping issue
	- Python Auto Garvage Collectiong
	- Data processing in memory at once
	- using wrong syntax
	- using one CPU
- Pandas way!
	- 다이어트 전략
	- 전략 1 : 식사량 조절, Memory Optimization
	- 전략 2: 식이요법, Enhancing Performance
	- 전략 3 : 습관, Adopting convension   
- 국민건강보험공단(NHIS)에 제공하는 데이터 4억 중 일부를 전처리
- 1) 식사량 조절
	- 큰 사이즈의 데이터 메모리 사용을 최적화
		- 문자열로 된 데이터를 숫자/영어로 변환
	- 데이터 형식 변환
		- 판다스는 고정된 바이트 유지
		- 데이터 형식을 알면 dtype에 형식 지정
		- 데이터를 불러왔지만 크기를 줄이고 싶으면 astype
		- check_dtypes()
		- 메모리 사용량이 줄어듬
	- Category 데이터 형식 사용
		- R에서 factor가 python category
		- Object를 Category로 변환하면 메모리 사용량 크게 감소
		- 범주가 무수히 많은 경우엔 object보다 비효율적일 수 있음
		- Object는 2.3초, Category는 0.3초 
	- 파일 저장 포맷 변경
		- CSV는 string 기반이라 IO 효율이 없음
		- Meta data가 없어 연속성 가지고 사용 불가
		- hdf5, parquet, pickle, feather 등을 사용함
		- parquet가 압축 형태로 제공되서 좋음
		- 개인적으로 feather, pickle
		- 프로젝트나 협업 목적은 parquet, hdf5
	- 요약
		- 데이터 타입 형식 지정
- 2) 식이습관
	- 2-1. Vectorization
		- 벡터화 연산을 사용하면 반복문을 사용하지 않고도 모든 원소에 대해 반복연산이 가능
		- len(df)
		- .iterrows()
		- .apply
		- Pandas Series Vectorization
		- Numpy Array Vectorization
		- 넘파이가 더 빠름
		- `@np.vectorize`를 사용하면 Custom 함수를 vectorization해줌 
	- 2-2. 효율적인 알고리즘
		- Pandas의 수백개 메소드를 어떻게 조합하냐에 따라 시간이 다름
		- `.sort_values(ascending=False).head(5)` vs `.nlargest(5)` : 후자가 속도 10개 넘게 빠름
	- 2-3. df.apply()는 만능이 아님    
		- Custom 함수를 만들어 apply를 사용해 데이터 처리, 분석. lambda와 사용
		- List Comprehension
		- pd.Series.apply()
		- pd.DataFrame.isin
		- pd.DataFrame.query
		- np.isin
		- pd.DataFrame.merge
		- 아래로 갈수록 더 빠름
		- merge는 Database에 익숙
	- 요약
		- 반복문 사용은 피하고 Vectorization 사용
		- 수행 시간을 더 빠르게 하고 싶으면 좀 더 효율적 알고리즘을 고려
		- Custom 함수는 우선 apply, 오래 걸리면 Pandas built-in 함수를 찾아 조합해 사용
- 3) 생활 습관
	- Method Chaining
		- 가독성이 좋고, 성능이 좋음
		- 한계
			- DataFrame의 중간 체크가 어려움
			- 진짜 성능이 좋아지는진 물음표
		- 데이터를 줄일 경우 사용
	- inplace parameter
		- inplace 선호나느 사용자
			- 속도가 더 빠르고, 메모리를 더 효율적으로 사용한다
		- pandas Core 개발자는 inplace를 없앰. 실행 이후에 메모리에 데이터에 남음    
		- 데이터를 일부먼 수정할 경우 사용
- 기타 유의사항
	- Case by Case
	- Garbage collection
		- delete를 주기적으로 하고 gc.collect 
	- Not designed for Big Data? 
- 스케일링
	- cuDF
- 실질적으로 바로 활용할 수 있는 꿀팁이 가능했던 세션, in보다 merge해서 보는게 더 빠르다는건 (SQL에서 자주 보던 방식이었지만) 신기했음

---

### 파이썬 3.7 어찌 그렇게 빨라졌나
- 정겨울님
- [발표 자료](https://speakerdeck.com/jungwinter/why-is-python-3-dot-7-fastest)
- 사실 과거 버전에도 계속 성능 개선은 있었음 
- 3.7은 릴리즈 노트에 Optimization을 꼭 집어서 말함
목표
	- 성능 개선을 위한 아이디어
	- 더 알고싶으면 어디를 볼지
	- 그래도 완전 어렵지 않은 C 코드 
- 기본 메소드 호출
	- 표준 라이브러리에 속한 클래스에 있는 여러 메서드들을 최적화함
	- METH_FASTCALL 컨벤션을 따르도록 바꿈
		- 생긴건 obcode처럼 생겼지만 사실 C 함수 선언 컨벤션
		- 파이썬 tuple이 PyObject의 C 배열로 들어옴
		- 더 알고싶으면 bpo-27810 
	- python 3.8에 positional arguments 개념이 동입됨
- Argument Clinic
	- 함수 변환과 생성을 도와주는 도구
	- CPython 내장 함수 인수 처리를 돕는 DSL
	- PEP-436 참고  
- 파이썬 시작 시간
	- 인터프리터를 실행하는 시간이 감소함
	- 맥 30%, Linux 10%
	- abc 모듈을 C로 다시 짬
	- site.py가 사용하는 sysconfig.py의 특정 함수를 import하지 않고 복사해서 사용하니 빨라짐
		- 인터프리터를 실행할 때 자동으로 import, site-package 경로를 찾고 추가
		- sysconfig의 함수를 site.py로 가져오는데 이게 무거웠던 상황
- 인스턴스 메서드 호출
	- positional argumnets 함수 호출에 대한 새로운 opcode 2개 추가   
- asyncio.sleep
	- asyncio.sleep()이 2배 빨라짐 => zero나 음수일 떄 빨라짐
	- 기존엔 delay가 0이면 바로 리턴인데, delay가 음수면 future 만들고 루프에 스케쥴링 했는데 안하도록 바뀜
	- 이 부분 생략하게 됨
	- sleep0은 그냥 yield만 있는 형태
- 이벤트 루프 만들기
	- asyncio.get_event_loop, get_running_loop 함수를 C로 짜서 4배 빨라짐
	- 캐싱 사용은 미미하고 os.getpid()대신 getpid()를 사용(C쪽) => 성능 향상 80%
- 동시에 실행하기
	- asynci.gather()가 15% 빨라짐
	- 마이크로서비스에서 하나를 받아 다른걸 처리 => 한번에 가져오도록 돌리게 해줌
	- 코루틴 하나하나를 functools.partial을 제거
	- 다 끝났을 때만 로직을 실행
- asyncio.ensure_future
	- 1.17배 빨라짐
	- if문 순서를 바꿔서 성능이 개선됨
- typing 모듈 가져오기
	- 제네릭 형식을 더 잘 지원하기 위해 특수 메서드 추가   
	- 던더메소드는 경고없이 깨질 수 있다고 함
- 리스트 정렬
	- 40~75% 개선
	- 리스트를 정렬할 때 대부분 값들이 서로 동일한 타입이라 가정
	- 매번 값을 비교할 때마다 타입 검사하지 말고 한번만 해두자가 아이디어
	- 여러 가정을 세우고 pre-check stage를 만듬
	- 아주 최악의 경우 pre-check 때문에 15% 느려짐(safe_object_compare로 넘어가기까지)
- 딕셔너리 복사
	- dict.copy()가 5.5배 빨라짐
- 정규표현식
	- case-insensitive matching이 20배 빨라짐 
- 파이썬 그 자체에 관심을 더 가지면 좋겠다고 생각하도록 만들어준 세션  	

---


### 머신러닝 및 데이터 과학 연구자를 위한 python 기반 컨테이너 분산처리 플랫폼 설계 및 개발
- 신정규님
- [발표 자료](https://www.slideshare.net/inureyes/python-164418964)
- 2015년 리뷰
	- 연구자 및 교육자를 위한 계산 및 분석 플랫폼 설계
- 현대 과학 연구와 개선
	- 학계와 업계, 사회의 간극이 존재한다 생각
	- 재현 가능한 데이터 연구 플랫폼 만듬
	- 논문용 코드가 쉽게 스케일업되는 서비스!
- 컨테이너 기반의 고밀도 분산처리 플랫폼 및 사용자 편의 기능 구현!!하자고 했음(프로토도 있으니..)
- Backend AI
	- [Github](https://github.com/lablup/backend.ai)
- 용어 설명
	- Baremetal
		- 가상 머신. 안에 있는 VM은 격리된 환경에서 삼
		- Shared : OS, Container Layer, Container
		- 컨테이너 : 호스트 운영체제 커널을 공유
		- 구현
			- Container layer : LXC, runC, Jail
			- 컨트롤 그룹을 사용해 구현
		- 클라우드 매니저
			- 클러스터에 VCM 또는 스토리지 생성
			- IaaS 구축을 위한 소프트웨어
		- 컨테이너 관리 솔루션
			- 컨테이너를 생성, 삭제, 배치, 관리하는 역할 담당
- 권불 10주
	- 이 바닥은 10주마다 바뀐다
	- Rootless 컨테이너 및 특화 컨테이너 솔루션의 등장
	- 마이크로서비스의 대두
		- 어플리케이션을 작은 단위로 쪼갬
		- 서비스 모듈 + 통신
		- 빠른 버전업 및 지속적 통합 
		- 기반 언어의 변화, 프로토콜도 확장
	- 비동기 시대
		- Asynchronous IO의 도래
		- 마이크로서비스 : 지연 시간 예측 난도
		- 많은 마이크로서비스들이 비동기로 동작
- 우공이산
	- 기본 설계하기
	- 오픈소스화 하다보니 다양한 사람들의 환경을 지원해야 함
	- 머신러닝 모델 대비!
		- 허나 Tensorflow 등장하고 난리남
		- 하위호환성 안줘 ㅠ
	- nvidia-docker도 바뀜
	- PyTorch의 등장
		- 버전마다 구현체가 다름
- 설상가상
	- 문제를 해결하면 새로운 것이 또 따라옴
	- 병렬화
		- GPU가 계속 놀아요 ㅠ_ㅠ
		- 데이터 병렬화나 모델 병렬화
		- 데이터 파이프라인도 싱글 노드 - 멀티 GPU, 멀티 노드 - 멀티 GPU에 맞춰 처리
	- 연구분야
		- 세상의 속도가 다르게 흐르는 곳
		- 아직도 Python2... 2를 지원해야하네
		- TensorFlow Extended 이런거 최근까지 python2까지만 지원됨
	- Python 2/3 징원
		- 인터페이스를 어떻게 하지?
	- ZeroMQ
		- 거의 모든 언어로 구현체가 존재!
		- 지원 언어가 15개 이상 되니 대환장
	- Kernel Runner
		- 컨테이너의 운영체제만 영향을 줌
		- 장점 : 백엔드 AI 에이전트는 3.6으로 하고 안에는 다른거도 가도 됨
		- 배포할 떄 계속 문제.. 
		- 그래서 Embeded Kernel Runner로 씀
- 화룡정점
	- 언어별 SDK 구현. 기존 구현체들은 너무 방대
	- 오프라인 환경
		- pip는 항상 온라인이..
		- Builder 만듬
		- Ansible로 배포 자동화
	- GUI
	- 코어
		- Webcomponent 기술 기반
	- 메인 앱
		- 장고 기반
	- 파이프라인 앱
		- 별도 개발해서 통합 예정
	- 앱
		- Electron 기반
		- JavaScript ES6 코드 서빙   
	- 웹 콘솔 모드
		- Consoel-server와 결합
		- Manager 프록시
		- 웹소켓 프록시
	- 허브
		- 전체 클러스터 관리용
	- 고가용성
		- 매니저가 왜 3개씩 존재하지 않나?
		- 로드 밸런서 구현
		- Fleet 운영시 Voting 알고리즘으로 대장 선정
		- 웹소켓 프록시 터널링을 사용해서 ssh 터널링 쓰는데.. 자꾸 사용자 환경에 깔기 싫다! 해서 웹에서 아답터를 위해 프록시 터널링 설계해서 구현함
- 홍익인간
	- GPU 가상화
	- fGPU 구현 및 테스트
		- 하나를 가상화해서 여러개처럼 사용해보니 이게 더 빠르네?
		- 우리의 코드는.. GPU를 괴롭히지 못함 나눠서 멀티로 하는게 더 빠름  
- 어마어마하다..ㅋㅋㅋㅋㅋㅋㅋ 고생하신게 엄청 보였고, 그 기간에 다 하셨다는 것도 대단..


---


### 추천시스템, 이제는 돈이 되어야 한다
- 최규민님
- [발표 자료](https://www.slideshare.net/ssuser2fe594/ss-164511610)
- 앞에 좀 못들음 ㅠ
- 어떤 MAB 알고리즘이 가장 좋은 성능을 내는가?
	- 대부분 추천 시스템에서 TS-MAB가 가장 좋은 성ㅇ능을 발휘함
- 엡실론 그리디 MAB
	- 기본적 Bandit 알고리즘
	- 작품별 CTR 예측
	- Best Arm 선택
	- 탐색과 활용이 적절한가?
	- CTR이 낮은 작품의 impressions별 CTR 신뢰 구간을 보자
	- Impression이 많아질수록 CTR이 수렴함이 보임
	- 10M Impressions
	- 추천될 수 없는 작품, 즉 Optimal Arm이 아님에도 계속 Impressions을 소비함(regret:손실 증가)
- 톰슨 샘플링
	- 엡실론 방법은 작품별 impresson 양을 동일하게 부여했지만, 이건 작품별(Arm)별 베타 분포로 샘플링
	- a=click, b=unclick 
	- 1000개부터는 점점 CTR 수렴
	- 추천될 수 있는 최소 CTR이 15%라 가정하면 작품 1번은 100 impressons까지만 trial되고 그 이후엔 서택되지 않음
	- 적절히 신뢰할만한 impression이 모이면 탐색 -> 활용으로 전환
	- CTR이 25%이상 작품은 계속 탐색하고 수렴
		- 빠르게 수렴 및 빠르게 engage
	- 실제 웹툰 작품들의 베타 분포 변화
		- 계속 탐색함
		- 신뢰 구간이 점점 좁아지며 수렴하는 작품들이 생김
	- 해석
		- CTR이 낮은 작품(Arm)들은 적당히 탐색하다가 추천을 하지 않고, CTR이 좋을 것 같으면 계속 탐색
	- TS MAB는 탐색&활용 Trade-off에서 적절힌 Reget(손실)을 최소화
- User Clustering
	- 작품의 CTR은 유저 성향별로 다름
		- 유저 A : 25% (30대 액션물 좋아함)
		- 유저 B : 2.1% (순정 만화를 좋아하는 여성)
		- 유저 C : 7.1% (모든 만화를 좋아하는 남자)
		- 유저별로 CTR이 높을 작품을 추천하면!
	- 모든 유저별 X 모든 작품에 대해 CTR 측정이 필요함
	- 그런데 모든 경우에 대해 CTR 측정은 불가능
	- 그래서 유저 클러스터링함
	- CTR이 비슷할 것 같은 유저끼리 모으고(8개)
	- 그 내에서 CTR을 예측 
	- 어떻게 클러스터링하는가?
		- 웹툰을 열람한 성향이 있다고 가정
		- 유저가 최근 읽은 작품들
		- 읽은 작품으로 CB(image, Text)를 Feature로 User Feature 생성 => 유사한 유저끼리 클러스터링 
	- 이 8개의 클러스터가 유저의 성향을 적절히 반영하는가?
		- 알려진 스코어가 잘 measure 안되서 정성적 탐색을 함
		- 유저클러스터 결과
			- 성별 분포
				- 각 클러스터별 성별 편향성이 뚜렷함
				- 여성 중심 / 남성 중심 / 여성 & 남성 혼합
				- 각 클러스터별 어떤 장르가 많이 소비되는지 파악
			- 클러스터별 소비만화 Tag들 파악
- 개인화 홈 추천
	- 클러스터 할당
	- 추천할만한 작품 Targeter
	- MAB를 통해 후보 작품을 Ranking 
	- 광고 시스템과 비슷함
	- 유저클러스터 + MAB 적용
- 연관추천 - ViewerEnd 추천
	- 목적 : 현재 읽고 있는 작품과 유사한 작품 중에서 열람수를 늘리기 위해 CTR(%)이 가장 높을 작품 추천
	- 사용되는 추천 모델들
		- item feature
		- MAB  
	- 비슷한 작품 Targeter => 작품 Ranker
	- 현재 본 작품과 설명이 유사한, 썸네일이 유사한 것을 추천 
	- item feature
		- 대표 이미지, 작품 제목, 설명, 유저 Feedback으로 작품간 상관 특징 추출
		- Image로 Style 특징점을 추출해 스타일이 유사한 작품 추출
		- Image로 Object Detection Task를 통해 특징점을 추출해 Image Object가 유사한 작품을 뽑음
		- Word2Vec으로 작품의 제목, 설명으로 특징점을 추천
		- Matrix Factorization(ALS) with implicit feedback 사용
	- 유사 작품 + MAB
- 구매 전환을 최대화하기 위한 실험들
	- 열람 중심 => 구매 중심 
	- 이제는 돈을 벌고 싶어요!
	- 열람 중심은 전체 열람(Clicks) 합이 최대화하도록 구현
	- 구매 중심은 유료 열람(Use Coin)합이 최대화
	- 실험 1. 매출 중심 MAB
		- Rewardd : Use Coin
		- 열람 전환율
		- 구매 전환율 
		- 결과
			- 폭망 ㅠ
			- 실험군(Beta)는 대조군(Alpha) 대비 -20% 떨어짐 => 실험 종료
		- 왜 그럴까?
	- 실험 2. Conditional Bandit 실험
		- 사건의 종속성 반영
		- 첫번째 MAB : Reward=Click(무료 열람)
		- 두번째 MAB : Rewardd=Use Coin 
		- 결과
			- 실험군의 대조군 대비 유료 열람수의 변화는 없음
			- 두번째 MAB의 수렴성이 보장되지 않음 
	- 실험 3. Retention Model
		- 리텐션이 높은 작품을 추천해보자
		- 작품마다 열람지속 스코어 측정
		- 열람지속 스코어가 높은 작품을 연관추천 추가해 MAB 수행
		- 결과
			- 열람 전환율(CTR)은 지표 상승
			- 구매 전환율은 변화 없음
	- 실험 4. Seen decay
		- 유저에게 노출했는데 클릭하지 않는다면 해당 작품에 대한 Negative Feedback
		- 안보면 패널티를 주자
		- 실험 결과
		- 대조군 대비 실험군의 CTR은 상승했지만 구매 전환율은 변화 없음 
	- 그물외 다양한 실험들 많이 해봄
	- 다시 고민
		- 왜 실험의 구매 지표 개선이 없지?
		- 컨텐츠 사용자의 구매 패턴부터 다시 분석
	- 독자들은 어떻게 유료 작품을 열람할까?
		- 추천을 보고 - 클릭 - 무료 열람 - 지속 열람 - 유료 열람
		- 엄청 긴 퍼널을 가지고 있음
		- 노출 대비 유료 전환율은 0.1% 이하로 매우 낮음     
		- 무료에서 열람까지 걸리는 시간은 평균 4.56일.. 좀 길다
	- 구매 전환율은 매우 낮고 구매 Feedback은 매우 지연됨
		- 구매 최적화를 위한 AB 실험의 지표
		- 추적과 측정이 어려움
	- 지금 개인화/연관 추천은 읽지 않은 작품을 추천
		- 최초 열람 유도가 지속열람, 유료 열람에 상관관계 또는 인과관계가 있는가?
		- 또 해봄
		- 연속적 열람 전환율이 어떻게 되나?
		- 추천과 비추천 로직의 변화가 있을까?
			- 베이스(에디터픽) 대비 CTR 242%
			- 4회 전환율은 42%
		- 구매 전환율은 추천에 인과관계가 있지만 작품의 품질과 유료 결제 경험에 의존적임  
- 목적
	- 개인화/연관 추천은? 열람 작품 늘리기
		- 초급 
	- 타켓팅 푸시? 지속 열람장의 유료 전환
		- 중급 

- 현재 소프트 클러스터 방법 쓰고 있음
	- 내가 드라마 좋아할 확률 30%, 액션 20% 여러 토픽을 가진 클러스터로 구성함
	- 정성적으로 하고 AB Test용으로
- 추천 안되는건 어떻게?
	- 작품의 다이버시티를 이용하고, 여러 풀을 섞음
- implicit als
- 앞 극초반부는 못들었지만 이미 알던 내용들이라 다행, 전반적으로 매우 좋았음. 국내에서 추천, MAB를 잘하는 팀은 이 팀이 아닐까 생각된다..! 따로 시간내서 규민님이랑 오랜만에 담소했는데, 역시 즐거운 시간이었음


---


### 꼬마 모차르트가 되어보자
- 김준우님, 한상곤님
- [Github](https://github.com/datakun/StudyMagenta)
- 인간과 기계가 차이가 없는 느낌
- 재미있는 프로젝트를 하고 싶었음
	- TensorFlow의 Magenta
	- 이것도 알리고 예술적인 것들을 해봅시다!
- 구글에서 바흐 탄생 기념일에 뭔가를 만듬
	- 소프라노 악보를 만들면 코드를 배치해줌
	- 미디 파일을 찾아보자!
		- www.vgmusic.ocm 8bit 음악이 많음. 학습용 이외엔 쓰면 안되요..!
		- 8bit midi 파일을 만듬
		- 상용 불가
- 미디파일을 합법적으로 구하는 방법을 시작하겠습니다
	- 발표 톤 너무 웃겨욬ㅋㅋㅋㅋㅋ
	- [magenta colab](https://magenta.tensorflow.org/demos/colab/)
	- latent loops
		- 멜로디 4개를 학습, 새로운 패턴이 나옴
	- 피아노징
		- 8개의 버튼으로 그럴듯한 연주를 하게 해줌
	- Neural Drum
		- 4박자만 패턴 입력하면 나머지 기계까 완성
	- PIANO scribe
		- 피아노 들려주면 midi로 바꿔줌   
- 마젠타는 파이썬으로 해볼 수 있겠다!
	- 윈도우에선 잘 안되서 WSL 선택
	- 단점 
		- 토이 프로젝트엔 괜찮지만 WSL1은 커널이 위에 올라가서 느림. WSL2는 성능이 좋아질거라 보임
	- Onsets and Frames 모델을 이용해 추론
- 마주친 문제와 해결
	- 파이썬 2.7 ㅋ
	- 소리내기 위한 pyfluidsynth가 2점대만 지원
- Demo 보여줌   
- 마젠타 라이브러리가 신기했고, 새로운 분야에 대해 알 수 있어서 좋았음



---


### Advanced Python testing techniques
- 안재만님
- [발표 자료](https://jaeman-static.s3.ap-northeast-2.amazonaws.com/pyconkr2019_AdvancedPythonTestingTechniques.pdf)
- 테스트 코드
	- 내가 쓴 코드가 잘 자동하는지 확인하는 코드
	- 프로젝트의 규모가 커지고, 참여하는 사람이 늘어날수록 반드시 필요
	- 마음의 안정감을 가지고 프로젝트 유지보수가 가능
- pytest
	- 조금 더 powerful
	- assert문 사용 가능
	- 더 자유로운 fixtur e사용 지원
	- 테스트 실패할 때 uniitest보다 유용한 정보 제공
	- 315+개의 플러그인 존재
- function 베이스로 테스트
- Fixture 사용하기
	- 다른 곳에서 정의하면 테스트 코드에서 사용할 수 있음
- 기본적인 API 테스트 구현
	- 유저가 가입하고 실제로 성공했는지 확인
- 복잡한 API
	- response가 200이고 유저가 있고 아이디가 있고 등등... 테스트 코드가 읽기 어려워짐
	- 어려워서 주석을 달았지만.. 도움은 안됨
	- 관리자가 ban시키고 되는지 확인하는 테스트는?
		- 아까보다 더 복잡함
	- 유저가 가입한 후 관리자가 승인하고 밴 시키고 로그인 안되는데 탈퇴 시도 성공하는데 재가입시 24시간동안 가입이 되지 않는것 테스트
- Sure를 이용해 더 직관적으로 테스트코드 구현
	- Assertion을 쓰기 쉽게 해주는 라이브러리
	- CPython에서만 사용 가능
	- Number, String, Collection, Callable 등에 대한 assertion 지원   
	- 가입한 후 관리자가 승인해야만 제대로 로그인되는지 테스트하는걸 더 직관적으로 가능
	- should.have.key
	- which.should
- BDD를 이용해 더 간단하고 재미있게 테스트 코드 구현하기
	- Behavior Driven Development
	- TDD와 유사
	- 테스트 코드보다 비즈니스 요구사항에 집중하자
	- 지원되는 Library
		- behave, lettuce, pytest-bdd
	- 먼저 자연어로 테스트 코드를 작성
	- Feature : 테스트할 대상 기능
	- 시나리오 : 테스트 상황 설명
	- Given : 테스트에서 사용할 데이터 컨텍스트
		- Backgoround : 공통적으로 사용되는 데이터, 컨텍스트
	- When : 수행할 조건
	- Then : 결과  
	- login.feature를 정의하고 시나리오 작성
	- Parametrized testing in BDD
		- 어떤 name의 약은 색이 뭐고, 어떤 결과엔 True, False 등
	- BDD 사용시 유의점
		- 지금 발표 보면 오 BDD 짱! 이지만 단점이 있음
			- 자연어로 define된 시나리오와 python 테스트 코드가 분리되어 있어 찾기 어려움  
				- IDE 도움을 받자
			- 최대한 재사용 가능한 문장으로 테스트 구성
				- 예 : 가입에 성공하고 로그인을 한 유저가 있다 => 정상 가입을 한 유저가 있다. 유저가 로그인을 한다
			- When에서 동작을 수행한 return 값은 Then에서 가져올 수 없음
				- Given에서 context 만들어놓고, When에서 수행한 동작을 context에 저장하고 Then에서 확인  
- 오늘부터 인증 서버를 분리해 새로 구현합니다
	- 로직 변경
		- 테스트 코드의 존재로 리팩토링을 안정감 가지고 진행할 수 있음
		- 1) 테스트용 인증 서버를 올려야겠다
		- 2) 항상 떠있는 개발 서버?
	- HTTP Mocking
		- Mocking : 가장의
		- HTTP Mocking : 발생하는 HTTP Call을 interrupt하여 실제로 HTTP Call을 보내지 않고, 정해진 동작을 수행해 response를 반환하도록 함
		- Python : HTTPretty
	- Monkey patching
		- 런탕임에 정ㅇ의되어 있는 클래스나 모듈의 attribute를 바꿈
		- 테스트 코드에서 많이 활용
			- A 모듈을 테스트, B 모듈에서 나온 결과는 항상 같은 값으로 고정
		- HTTPretty도 Monkey patching을 이용해 구현되어 있음
		- B는 import하지 않고 고정된 값을 가져오고 싶은 경우 사용
	- 데이터를 받아 예측하는 코드 예시
- 모든 경우
	- 수동으로 모든 경우를 테스트할 수 없음
	- 랜덤한 input에 대해 function이 리턴해야할 값이나 수행할 동작을 테스트
		- 어떤 input이 들어와도 error가 나면 안됨
	- QuickCheck : Randomized testing(하스켈)
		- python은 hypothesis library
	- given으로 랜덤한 input을 받도록 만들어주는 데코레이터
	- strategies는 랜덤하게 주어질 input의 규칙
	- 머신러닝 모델
		- 나이 예측 ML 모델에서 나온 나이 값이 0에서 100 사이인지, contribution이 0에서 1사이인지
- 너무 오래 걸리는 것 같아요
	- Benchmark test
		- 함수를 수행하는데 걸린 시간 측정
		- 1초에 몇개의 요청을 처리할 수 있는지 근사
		- 다수아 사용하는 실 서비스 환경에서 반드시 필요
		- 많이 노출될 API 
	- Basic 패턴 : start.time 사용하곤 함
	- benchmark로 감싸주면 더 편하게 가능   
- 그 외 유용한 툴
	- 벤치마크가 부족하면 Profiling 툴 사용(pytest-profiling)
		- 함수별 execution graph와 실행시간 보여줌
	- N대의 서버들이 부하를 얼마나 버티는지 알고싶어요
		- http://locust.io 
- 간단한 pytest plugin 만들기
	- goconvey
		- 로직을 바꾸면 실시간으로 테스트 성공 실패를 웹으로 알려주는 툴
		- python으로 구현하려고 하는데 아직 못만듬! 내년에 꼭 소개드리겠습니다
		- pytest-convey
			- pytest-watch로 감지, pytest-json-report로 포맷팅  
- 정리
	- 테스트 코드를 작성하기 쉽게 만들어 두는 것이 굉장히 중요
	- 테스트코드 리팩토링
		- Top-down 방식으로 일단 코드 작성
	- 테스트에 유용한 라이브러리 상용
		- Sure - assertion 알아보기 쉽게 작성 가능
		- BDD
	- 기타 방법
		- HTTPPretty, Randomized, Monkey Patch   
- 꿀팁을 많이 얻을 수 있어서 매우 좋았음!!  

---


### gRPC와 python을 활용한 Microservice 개발기
- 송지형님
- MSA, gRPC 등
- [발표 자료](https://drive.google.com/file/d/14eYzUySeW5n1n0u7r0IYUqwsK75F_W2V/view)
- 클라우드 엔지니어로 시작
- 메가존 클라우드의 고민
	- 고객들에게 좀 더 가치를 전해줄 수 있는 것이 없을까?
- 안정적이고 확장 가능한 플랫폼
- MSA
	- 새로운 Feature가 느슨하게 연결되어야 함
	- MSA : 하나의 어플리케이션을 작은 서비스로 나누고, 프로세스를 가지고 가벼운 메커니즘을 사용해 HTTP resource API
	- 서비스간 독립적 형태로 존재
	- 유연한 대처가 가능
	- 서비스별 별도 기술 적용 가능
	- 자바, 파이썬, 노드 모두 가능
	- 대부분 RESTful API를 통한 서비스 통신
	- 단, Service간 Network를 통한 통신
		- 통신 Overhead 증가
		- 서비스별 다른 언어 사용 가능이 진짜일까? 생각보다 쉽지 않음
- gRPC
	- High performance, open-source universal RPC framework
	- 통신 오버헤드를 최대한 줄이려는게 목적
	- pluggable support : 여러 플러그인을 사용 가능
	- 구글이 개발한 RPC 기반 Framework
	- MSA와 같은 분산 구조에 적합한 효율적인 통신 프로토콜에 대한 고민    
	- Remote Procedure Call
		- 원격지의 프로그램을 로컬에서 실행하는 것처럼!
		- Code의 간결함
		- RESTful의 HTTP 규격 불필요
		- 다시 돌아온
	- 특징
		- 프로토콜 버퍼
			- 구조화된 데이터를 시리얼라이즈하기 위한 flexible, efficient, automated 메커니즘
			- 메세지 처리 기술인데 더 작고 빠르고 심플
		- 서버 클라이언트간 메시지를 정의하는 역할
			- 실제 통신시 byte stream으로 데이터를 인코딩해 통신
			- XML보다 3~10배 작고 20~100배 빠름
		- HTTP/2
		- 커뮤니케이션, 양방향
		- response도 정의 가능
	- Server Implementation 
	- MSA에 특화된 Service간 Message 성능 향상에 집중한 RPC Framework
	- Protobuf 관리가 쉽지 않음
	- gRPC를 잘 좀 써보자
		- API
		- Pkg -> proto -> Build -> Dist -> Template
		- Protobuf 관리
			- API source 받아서
			- /proto 디렉토리에 작성
			- makefile 작성
- 비즈니스 로직에 맞도록 진행
- 마이크로서비스, gRPC에 대한 깔끔한 설명을 해주셔서 좋았음

---

### 온라인 뉴스 댓글은 정말 사람들의 목소리일까? - PART2
- 이준범님
- [발표 자료](https://speakerdeck.com/beomi/pyconkr-2019-onrain-nyuseu-daesgeuleun-jeongmal-saramdeulyi-mogsoriilgga-part2)
- 데이터 크롤링 : 10분 단위
- AWS 클라우드 위에서 처리
- 직접 데이터 수집 - 처리 - 가설 - 라벨링 등에 대해 잘 나와있음
- 역시 준범님!


---

### 더 읽은 자료
- [100억건의 카카오톡 데이터로 똑똑한 일상대화 인공지능 만들기](https://speakerdeck.com/codertimo/paikon-2019-100eoggeonyi-kakaotog-deiteoro-ddogddoghan-ilsangdaehwa-ingongjineung-mandeulgi) : 연구 시작 ~ 진행 과정을 잘 알려줌. NLP에 큰 흥미는 없지만 재미있게 읽을 수 있었음
- [파이썬 웹서버 REST API 문서 쉽고 빠르게 작성하기](https://www.slideshare.net/YongseonLee1/pycon-korea-2019-rest-api-document-generation-164504789) : 언젠가 API 문서화를 고민할 때 다시 읽어보면 좋을 것 같은 문서
- [from banksalad import python](https://speakerdeck.com/sunghyunzz/from-banksalad-import-python) : 뱅크샐러드가 파이썬을 활용해 어떻게 발전해왔는지 알 수 있는 문서
- [Pickle & Custom Binary Serializer](https://www.slideshare.net/YoungSeokKim8/pycon-kr-2019-pickle-custom-binary-serializer) : Serialize에 대해 알 수 있는 문서

---

### 튜토리얼 자료
- pytest로 파이썬 코드 테스트하기
	- [슬라이드쉐어](https://www.slideshare.net/ssuser80e030/pytest-164575856)
	- Tutorial 자료, pytest를 사용한 기본에 대해 잘 나와있음   
- Python으로 지리공간데이터 다루기
	- 아직 발표자료 미공개인듯. 추후 확인해보기 


### 행사 부스
- 프로그래머스 구구단 구현 이벤트
	- 올해는 프로그래머스 구구단 구현 이벤트에 참여함
	- [코드](https://nbviewer.jupyter.org/github/zzsza/funny-pycon2019/blob/master/gugudan/gugudan.ipynb)
	- 초반엔 1등했으나 마감일에 갑자기 다크호스분의 등장으로 2등
		- 1등분은 파이썬 로고를 만드셔서 리스펙.. 저도 좋아요 눌렀음
	- 그리고 에어팟 받아서 만족 :)
	- 오랜만에 본 광고동아리 선배님도 계셔서 반가웠음-! 
- 스캐터랩 연애 시뮬레이션
	- 쿼리와 센텐스, 감정 결과가 주어지면 어떤 답을 해야하는지 문제가 있었음
	- 사실 약간 시도하다가 막혔지만, 영상이 매우 고퀄이라 재미있게 시도해봄
	- 확실히 자연어쪽을 세련되게 잘 한다는 느낌을 받았음  







 