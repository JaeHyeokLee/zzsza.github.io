---
layout: post
title:  "DEVIEW 2019 1일차 후기"
subtitle:   "DEVIEW 2019 1일차 후기"
categories: etc
tags: lecture
comments: true
---

네이버 DEVIEW 2019 1일차 후기입니다 :)


### 키노트
- 문재인 대통령님이 오셨음


### 외산 클라우드 없이 AI 플랫폼 제공하기: features, training, serving, and AI Suite.
- 어떻게 설계했는지 위주를 말씀드릴 예정
- [발표 자료](https://deview.kr/data/deview/2019/presentation/%5B141%5DDeview2019_AiSUITE_1028_1.pdf)
- 자체 AI 플랫폼이 필요한 이유
    - Security
    - Cost
        - 데이터가 적거나 연산량이 적게 필요하면 클라우드 사용이 유리할 수 있음
        - 대용량 데이터 처리를 지속적으로 수행하면 비용 무시하기 어려움
    - Demand
        - 머신러닝 수요가 엄청 늘어남
- 이미 존재하는 플랫폼
    - 분산 저장 플랫폼, Cuve
    - 분산 처리 플랫폼 : C3
    - 피쳐 엔지니어링 플랫폼은 없음
    - 모델 학습 플랫폼 : AiTraining NSML
    - 모델 서빙 플랫폼 : Ai Serving Platform
    - AI Suite : End-to-End Platform
    - 구글클라우드와 비슷
- 머신러닝 하나 적용하기 위해
    - 데이터 처리
    - 모델 학습
    - 서빙 : 성능 평가와 용량 산정 후 서비스로 제공
    - 데이터를 가져와서 인프라 만들고, 비즈니스에 적용하는 시간이 오래 걸림
- AiFeatures
    - 웹브라우저로 카테고리처럼 어떤 데이터가 있는지 볼 수 있음
    - DUMP : 데이터를 어딘가로 가져와서
    - ANALYZE : 잘못된, biased 데이터 없나 보고, 간단한 가시화로 데이터에 대한 인사이트를 얻고
    - BATCH : 잘못된 데이터는 버리고, 나머지는 가공해서 피쳐벡터를 만듬
    - AiFeatures 아키텍쳐
        - <img src="https://www.dropbox.com/s/cg72zq2pyooh9om/Screenshot%202019-10-28%2011.52.14.png?raw=1">
        - Facets 씀
        - 참고 : [https://nbviewer.jupyter.org/github/zzsza/TIL/blob/master/Tensorflow-Extended/TFDV(data validation) example.ipynb](https://nbviewer.jupyter.org/github/zzsza/TIL/blob/master/Tensorflow-Extended/TFDV%28data%20validation%29%20example.ipynb)
    - Facets 사용할 때 샘플링, HDFS를 위해 일정 부분 읽어서 전체 추론
    - NLP 라이브러리를 API화시킴. 웹 서버가 Rest API로 요청하고, nginx로 쓰로틀링하고 pyspark는 쓰로틀링 프록시로 다 보냄
    	- pyspark로 딕셔너리 물고 하는 것들을 할 수 있음
    	- UDF 만들어서 해결 
- 머신러닝 모델 학습
	- 모델 연구시
		- 빨리 학습하고 평가하는 과정을 반복
		- 모델과 파라미터를 빨리 얻는 것이 목적
		- 데이터는 고정되므로 캐싱하면 이득
	- 제품화 시
		- 학습에 걸리는 시간을 이미 알고있음. 다음 갱신 전까지만 완료되면 되기 됨. 일정 시간 내에 최소 자원을 쓰면 좋음
		- 배포 전에 이전 버전의 모델과 품질을 검증할 필요가 있음
		- 켄진타우? 헤밍 디스턴스 알고리즘처럼 얼마나 서로 다른가
		- 매번 새로운 떼이터로 학습하는 경우가 많아 데이터 캐싱 이득이 없음 
	- 학습 자동화
		- <img src="https://www.dropbox.com/s/8gtt5ioqnvxdjbg/Screenshot%202019-10-28%2011.55.28.png?raw=1">
- 서빙 아키텍쳐
	- ONNX 형태로 받음 => Pytorch/Caffe 모두 가능
	- 비즈니스 코드 => 사용자의 코드 => 뒷단 서버에 요청
	- Yarn 위에서 돌리고 있음
	- <img src="https://www.dropbox.com/s/2gcm2m9ovy96l9k/Screenshot%202019-10-28%2011.56.49.png?raw=1">  
	- For ML Engine : 내 모델은 여기있고, 이 설정으로 띄워주세요
	- <img src="https://www.dropbox.com/s/57is3slpicflv2q/Screenshot%202019-10-28%2012.00.35.png?raw=1">
- 모든 단계 자동화하기
	- AI-suite 
	- Google Dataflow랑 비슷한 느낌? 드래그도 되는 편의성
	- <img src="https://www.dropbox.com/s/5buno7z4m38qt5a/Screenshot%202019-10-28%2012.03.02.png?raw=1">
	- Batch라는 주석을 하면 프러덕션 레벨의 셀 => 확장 프로그램을 Run하면 Batch만 파이썬 스크립트를 뽑아서 할 수 있음
- Problem 3. 사용자 작업이 돌고 있는데 AI Suite는 어떻게 업데이트하나?
	- 전체 컴포넌트는 컨테이너라이징
	- 분산 작업 관리는 Celery(Airflow 왜 안썼는지는 부스로..!)


---























