---
layout: post
title: "PyCon 2018 - 1일차 후기 및 메모"
subtitle: "PyCon 2018 - 1일차 후기"
categories: etc
tags: lecture
comments: true
---

PyCon(파이콘) 2018 1일차 세션 메모 및 행사 후기입니다!

---

## Pycon 2018 후기
- 파이콘도 3년차, 처음 파이콘 왔을 땐 데이터 관련 내용만 들었는데 작년부턴 자주 접하지 못하는 분야의 세션 위주로 듣고 있습니다. 바운더리를 한정하지 않고 확장하기 위해서!
- 1년차 때 비해 지나가다 아는 사람들을 자주 만나네요. 더 많은 분들과 교류하고 싶어요! 
- 내년에 발표자 신청하기. 개인 프로젝트 선정해보기
- 개발자 행사 중 규모가 꽤 있는 편! 다른 언어의 행사는 어떤지 궁금하네요. 종종 다른 언어 행사도 가봐야겠습니다
- 역시 개발자 행사 다녀오면 잠옷이 많이 생겨서 좋아요!
- 후원을 해준 다양한 회사들의 굿즈도 좋았고, 매년 상품 퀄리티도 좋아지고 다양한 이벤트가 진행되서 신나요!(코딩하는 문제들이 재미있었음!)
- 준비해주신 분들 고생하셨습니다. 내년 파이콘도 기대됩니다!

## 머신러닝으로 치매 정복하기
---

- 박세진님, 뷰노
- 한양대 컴퓨터비전 박사 과정ing


### 대상
- 머신러닝을 입문하고 자신만의 문제를 찾는 분
- 의료 영상

### 하지 않을 얘기
- 치매 정복은 못함ㅠㅠ
- 데이터에 대한 얘기

### 치매 연구의 목적, 방향
- 치매
	- 여러 원인으로 인지능력이 저하되어 일상 생활에 장애
	- 치료 불가하지만 진행을 늦출 수는 있음
	- 알츠하이머에 집중
- 알츠하이머
	- 치매의 가장 흔한 형태
	- 조직병리학적 특징 : 뇌위축(Atroph)
	- 진단 방법
		- 뇌 및 신경계 질환 분석
		- MRI, CT, ET 촬영
		- 상담
- 연구의 목적과 방향
	- 치매를 조기에 발견해 치료 제안에 도움
	- MRI 영상에서 뇌위축에 대한 정보를 제공하는 SW 개발  

### 해결 가능한 문제 정의
- 알츠하이머에 관련된 뇌영역을 **영역 분할**(Parcellation)
- 분할된 영역으로부터 **특징 추출**
- 정상인과 알츠하이머 환자 **특징 DB** 생성
- 특징 DB에서 특정 환자의 **비정상 수치** 산출
- 기존 뇌영역 분할 SW
	- Neuroquant
		- 분석 툴, 리포트, 시각화, 10분
	- Freesurfer
		- 분석 시간 6시간  
	- 문제점
		- 매우 느림
		- 현실의 데이터 복잡도를 완전히 반영하진 않음
		- 매우 복잡하고 단계가 많은 처리 방법 

### 접근 방법
- 차별점
	- 병원 진료 과정에서 사용 가능한 수행 속도
	- 한국인의 정상인에서 비교
	- 뇌영역 분할 수행결과를 시각화
	- 획기적으로 빠르게
	- 중간 단계를 최소화
	- 현실의 다양한 데이터 복잡도를 반영
- 해결책
	- GPU
	- End to End 지향
- Brain MRI 전처리 과정
	- Biase field correction -> Resample to 1mm lsotropic -> AC-PC Alignment  
	- 엄청 복잡
- CNN
	- Atrous convolution
	- ResNet
	- Dice loss
- 전처리
	- 사진 참고
- 파이썬 영상처리
	- ```opencv```가 가장 유명하지만 ```Skimage```도 좋음 
	- ```PIL```
	- ```Numpy```
- Object Detection
	- Faster RCNN vs Deconvolutional network
- Pixel Classification
- Data Imbalance
	- Positive, negative, class imbalance
	- Categorical weight balancing : Label의 비율대로 class별 loss 비율 맞춤
	- Dice coefficient loss
- High ResNet
	- No Pooling (Atrous Convolution이라!)
- 3D convolution
- 알츠하이머 예측
	- Volumne, ICV Percentile 기반
	- Biomarker 기반
- 임상 검증
	- 다양한 장비, 환경에서 재현성, 일관성 검증
	- 어떤 측도를 제시할 경우 현실적 정확도를 만족하는가
	- 과정이나 인과를 설명 가능한가?
		- 설명할 수 없다면 문제를 부분적으로 설명
		- A-B-C 인과 관계에서 B만이라도!

### 결론
- 왜 치매 연구를 하는가?
	- 치매 예방을 위해
- 해결 방안
	- 의료 데이터 불규칙성 극복
	- 객체 인식 기법
	- 3D 데이터 학습 

## Luigi로 Data Pipeline system 구현하기
---

- TRUE SHORT : 주식 정보(공매도 전문) 제공
	- CTO, 송은우님 
- 사내 데이터 파이프라인을 파이썬 스크립트와 크론탭으로 시작해서 Luigi로 업그레이드한 이야기

### ETL
- Extract, Transform, Load
- 시작은 파이썬 스크립트와 크론탭으로 시작
	- 처음엔 충분
	- 기본 데이터 취합
	- 데이터 분석/가공
	- 데이터 저장
- 그러나 시스템의 규모가 커지고, 데이터의 종류가 다양해지며  복잡해짐
	- 데이터가 준비되는 시점에 모두 틀림
- 실제 구조
	- <img src="https://www.dropbox.com/s/orr117ogswnvmp3/2018-08-18%2013.47.37.jpg?raw=1">
	- 데이터를 받아오는 스크립트를 각각 시점에 시간순으로 실행
	- 다 받아질거라 예상되는 시점에 랭킹을 계산하는 스크립트 작성  	
- 그러나 데이터를 외부 소스에서 받아오기 때문에 다양한 문제가 있을 수 있음
	- Error
	- 데이터가 준비되는 시간 지연
	- 데이터가 준비되어 있는지 Dependency 체크	    
- Depedency가 준비 안되었으면 Dependency 재실행
- 그 후 전체 로직 재실행
- 실제 로직보다 보일러플레이터 코드들이 많아짐

### What I Need
- Workflow 관리
- 즁복 작업 최소화
- 부분 실패 최소화
- Task 모니터링
- Dependency 그래프 시각화
- 보일러플레이트 코드 최소화

### Luigi
- ```luigi.Task```를 Super Class로 사용
- 파라미터 정의 / 명확한 Depedency 정의 / 비즈니스 로직 / Output
- [Luigi Github](https://github.com/spotify/luigi)
- 기본적으로 Airflow와 유사한 듯
- 스케일 아웃도 쉬움

### Luigi도 만능은 아님
- No central task trigger system
	- 루이지를 실행할 때, ```crontab``` 사용
- 분산 실행(Distributed Execution)은 우리 일
	- 여러 Task를 동시에 돌리는 것은 Luigi에서 지원
	- 동일한 Task를 워커에 나누어 작업하는 것은 미지원해서 직접 구현해야 함 
- 설정은 많으나 문서가 충분하지 않음

### Tips
- Dependencise들은 (가능하면) 최대한 심플하게
- Task는 최소한의 단위로
	- Extraction, Transfer, Load 모두 각각의 Task로 구분
- Noitification 또한 최소한 것만 설정


## PyQt로 만드는 웹기반 데스크탑 어플리케이션
---

- PyCon 2015, 2017 발표 
- [예제로 배우는 PyQt](http://opentutorials.org/module/544)
- PyQt : 상대적으로 나쁘지 않은 개발환경, 크로스 플랫폼 지원
	- But 지난 세대 디자인과 부족한 위젯 모듈 

### QWebEngine
- Web을 보여줄 수 있는 Qt Widget
- Qt4, Qt5 이후에 빠르게 변하고 있는 모듈
- [예제 코드](https://github.com/RavenKyu/OpenTutorials_PyQt/tree/master/QtFramework/QtWidgets/QWebEngineView)
- View만 띄운 거라 이벤트를 할 수 없음
- Chrome을 통한 웹 디버깅
	- QtWebEngine은 크로미움 기반
	- 실행시 옵션 추가 : ```sys.argv.append("--remote-debugging-port=8000")``` 
- 웹 View를 사용하는 대신 다 직접 만들어야 함
- 네비게이션바, 웹 표출단, 상태바
- 위젯을 따로 빼서 작성
- 웹 요청 처리
	- 새 창, 탭 생성 요청
	- 닫기 요청
	- 다운로드 요청
	- 프린터 사용 요청
	- Flash 사용 허가
	- 경고창 변경 

### QWebChannel
- PyQt와 Web을 서로 이어주는 역할
- 데이터를 전달하고 기능을 호출
- [코드](https://github.com/RavenKyu/OpenTutorials_PyQt/blob/master/QtFramework/QtWidgets/QWebEngineView/QWebEngineView_02_WebChannel.py)
- 동작 개요
	- 이미지
- 웹을 불러온 이후 웹에 QWebChannel 삽입하기
	- 웹브라우저 사용과 아닌 경우를 분리
	- [코드](https://github.com/RavenKyu/OpenTutorials_PyQt/blob/master/QtFramework/QtWidgets/QWebEngineView/QWebEngineView_07_print_request.py)
- QWebChannel에서 사용되는 데이터 타입 QJsonValue, QJsonDocument
	- 타입을 지키지 않으면 데이터를 주고 받을 수 없음 

## 하이퍼커넥트에서 자동 광고 성과 측정 시스템 구축하기
---

- 박승호님(데이터 엔지니어), 정강식님(CTO)	
- CTO님이 하이퍼커넥트 소개해주셨음
	- WebRPC 통화
	- 글로벌 인프라
	- 모바일 기기에서 딥러닝 가속 기술 사용
	- 아자르를 제외한 다른 앱에선 대부분 파이썬 백엔드 사용(생산성을 위해)
	- ML 관련도 파이썬 사용
	- 데이터 기반 의사결정 시 파이썬 사용
	- 아키텍쳐
	- <img src="https://www.dropbox.com/s/cr0lhg526ps3sch/2018-08-18%2015.59.42.jpg?raw=1">

### 자동 광고 성과 측정 시스템 
- 디지털 마케팅
	- 정량적 성과 평가 가능
	- 광고에 얼마만큼 지불, 노출, 광고를 통해 얼마나 들어왔는가 등 
- 슬랙 채널에 Report 알림을 붙여서 제공
- ROAS 높으면 -> 유사한 광고 생성, ROAS가 안좋으면 광고 중단
- <img src="https://www.dropbox.com/s/8rk84cirr2d541k/2018-08-18%2016.02.16.jpg?raw=1">

### 아키텍쳐
- 스케쥴링 
	- cron : 디펜던시에 취약
	- Airflow
	- Daily Report 작성
- Ad Spending
	- 페이스북, 애드워즈 API를 통해서 가져옴
	- 페이스북 API를 사용해 가져오는 것 정말 쉬움!
	- 매체마다 다른 마케팅 용어를 통일
- Revenue(payment)
	- 결제 데이터는 트랜잭션 데이터베이스(MySQL)에 쌓임
	- 주기적으로 스냅샷을 찍어 테이블로 구성 
	- <img src="https://www.dropbox.com/s/kzhyhvjb4i5lrf6/2018-08-18%2016.13.43.jpg?raw=1">
- Revenue(user behavior)
	- 매출과 관련된 이벤트 로그도 측정
	- 프리미엄 매치를 하고 싶은데, 매칭 상대방이 없다면? 돈을 쓰고 싶어도 돈을 쓸 수가 없는 것! 
		- 매출에 기여한 유저라 판단
	- 서버 로그를 전처리 + 익명화 과정을 통해 원하는 테이블로 구성
		- <img src="https://www.dropbox.com/s/h2eplponbn20kfd/2018-08-18%2016.15.45.jpg?raw=1">
	- 실재 매출이 발생하지 않았는데 어떻게 추산할 수 있을까?
		- 서비스마다 다르고 경험적인 내용이 들어가야 함
	- Page Rank 알고리즘 
		- 영향력 있는 페이지를 보여주는 알고리즘
		- 영향력 있는 페이지가 인용할수록 해당 페이지의 PageRank가 올라감
		- 높은 매출인 유저와 매치하면 상대방 유저의 PageRank가 올라감
	- Shapely Value
		- 게임 이론
	- 서비스마다 매출이 될 수 있는 행동이 존재하지만, 그에 따라 적절한 알고리즘을 선택
- Attribution
	- 유저가 어떤 광고를 통해 앱에 유입했는지 파악
	- 각 매체에서 제공하는 SDK를 클라이언트에 추가 : 비용 감소, 개발 코스트 증가
	- Third Party Tool 사용 : TUNE, Appsflyer : 비용 증가, 개발 코스트 감소, 용량 감소
- LTV
	- 고객 생애 가치, 해당 고객이 평생동안 얼마만큼의 가치를 가질 것인가?
	- 고객 획득 비용(마케팅 비용) + 고객 매출(구매) + 고객 유지 비율(리텐션) 
	- LTV 계산 방법 : BG/NBD 모델
		- 가정1 : 고객은 일정한 비율로 구매하고, 고객마다 다른 비율을 가진다
		- 가정2 : 고객은 구매 직후 일정한 확류로 이탈하고, 고객마다 다른 확률을 가진다
		- 구매 빈도는 포아성 분포를 따르고, 고객간 이질성은 감마 분포를 따른다고 가정
		- Drouput Rate는 Geometric 분포, 고객간 이질성은 베타 분포
		- 구매 정보를 사용해 다시 구매할 확률과 이탈할 확률을 계산
	- Gamma-Gamma 모델 : 가격 관련 모델링
		- 가정 : 고객의 1회 구매 금액은 감마 분포를 따룬다. 고객간 이질성은 감마 분포를 따른다 
		- 파이썬에서 ```lifetimes``` 라이브러리 존재(다행)
- ToDo
	- 광고 성과에 따른 액션(광고예산, 입찰 수준 변경)을 자동화!
		- WIP : 광고 성과(Alert에 따른 마케터의 액션 수집중
	- 광고 노출 최적화
		- 서비스 인프라에 따른 광고 노출을 최적화
		- No-Pacing 광고와 Pacing 광고의 성과 비교 -> 독자적인 알고리즘 생성
	- 타겟팅 광고 자동화
		- 광고 성과가 좋을 것으로 예상하는 유저를 자동으로 타겟팅 
