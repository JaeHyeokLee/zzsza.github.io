---
layout: post
title:  "2017년 회고, 2018년 계획"
subtitle:   "2017 retrospect, 2018 plan"
categories: diary
tags: diary
comments: true
---


남에게 보여주기 위해서가 아닌, 나를 돌아보기 위한 글(따라서 반말)

# 2016년

2017년을 말하기 전, 2016년부터 살짝 언급하고 가야할 것 같다. 2016년엔 ```패스트캠퍼스```에서 데이터 사이언스 스쿨 과정을 수료했다. 사실 과거에 빅데이터 동아리 Boaz에서 활동해서 이론은 어느정도 알고 있었다. 단지 내가 R을 능숙하게 사용하지 못했던 점이 아쉬웠다. 그 아쉬운 점을 해소하기 위해 패캠을 찾아갔다. 파이썬을 처음 배우면서 데이터 분석의 재미를 찾아갔고 8월에 수료했다. 다른 동기들은 바로 취업을 하기 위해 원서를 넣었지만(물론 나도 조금 넣었지만) 10월에 인생 첫 유럽 여행이 계획되어 있어 진지하게 임하진 않았다. 그리고 어머니와 함께 간 유럽 여행은 정말 즐거웠고, 시야가 넓어졌다.

그 이후엔 데이터 분야에서 다양한 것들을 경험하려고 노력했다. 데이터 시각화를 위한 ```D3.js```, 데이터 분산처리를 위한 ```하둡```, ```스파크```, 웹을 만들기 위한 ```Flask```, ```node.js```, 그리고 데이터 경진대회인 ```Kaggle``` 까지 공부하고 이것 저것 만들다 2016년은 끝났다. 12월에 고민했던 것은 "대학원에 갈까?" 결국 가지 않기로 결정했다.  


# 2017년
## 1월 - 학교 도서관, 스밥 에디터
우선 취업에 대한 생각이 깊지 않아 졸업유예를 신청하고 학교 도서관에 매일 갔었다. 그 당시 학교에서 진행하는 해킹 수업을 들었는데, C를 처음 짜보며 아.. 파이썬 짱... 여태까지 코딩을 편하게 했음을 알 수 있었다.

페이스북 그룹인 ```스타트업, 식사는 하셨습니까?``` 라는 곳에서 1년 운영진을 뽑고 있는 글을 봤다. 스타트업의 다양한 분들을 만나는 것을 즐기고 글을 쓰는 것도 좋아하기 때문에 에디터에 지원했다. 매달 새로운 스타트업을 만나며 그분들의 열정에 자극받았다. 시선을 바꿔 그것을 사업으로 만드는 것. 정말 멋진 능력이라고 생각했다.


## 2월 - Datanada, Retrica
Tensorflow kr에서 ```John Park```님의 구인 공고를 보고 문의를 드렸더니, 회사에 와서 1주일간 ```Kaggle```을 해볼 생각이 있냐는 제안을 받았다. (심지어 공부하는건데 유급이었다!) 1주일간 신나게 캐글을 했다. 이 때 [후기](http://blog.naver.com/PostView.nhn?blogId=zzsza&logNo=220931599023)

그리고 동시에 카메라를 만드는 스타트업 ```Retrica``` 데이터 분석가에 지원했다. 위에서 말했듯이 취업에 생각이 크게 없어 가볍게 면접을 보러 갔다. 면접을 보러 갔는데 면접관분이 말을 너무 잘하셨다. 어디서 말과 논리로 지는 경우가 많지 않았는데  레트리카 COO님은 논리적이면서 말을 잘하셔서 회사에 대한 호기심이 +++! 되었다. 대표님 면접을 통해 기술적으로 배울 것이 많을 회사라고 생각했고 결국 합격해서 레트리카를 다니게 되었다.

그리고 월말에 ```9xd``` 행사에 가서 많은 분들을 뵙게 되었다. 그 이후에도 참여하고 싶었는데 인기가 너무 많아 참석이 어려웠다.

## 3월 - 적응기
회사에 들어와서 처음인 것이 너무 많았다. 우선 맥북, 구글클라우드 플랫폼. 조금씩 적응하며 회사에 필요한 것들을 진행했다

같은 직군인 분이 1분 계셨는데, 내가 들어갔을 당시엔 서버 개발자분이 웹에 뿌려주는 지표를 엑셀에 저장해 레포트를 만들었다. 웹에 있는 데이터를 복붙해서 엑셀에 저장하다보니(게다가 복붙할 양이 꽤 많았다) 완전 고생하고 계셨다. 크롤러 만들어서 csv로 떨구는 코드를 작성했다.

또 슬랙에 매일 주요 지표를 보내주는 bot을 만들었다. 이것도 참 간단한 일


## 4월 - Dashboard, BigQuery
회사에서 전체적 지표를 볼 수 있는 곳은 존재했지만, 무언가 편하게 볼 곳이 없어서 대시보드를 구축하는 일을 했다. 그리고 서버 개발자분이 하시던 일을 나한테 다 인수인계를 해주셨다(..) 그 때 서버 개발자분의 코드를 처음 보며 와.. 역시 초고수의 코드는 이런 것인가..(참고로 서버 개발자분은 카카오 출신이신데 현재는 go매니아) 코드 가지고 공부를 꽤 했다.
그리고 ```Superset```이라는 Airbnb에서 만든 오픈소스 가지고 대시보드를 만들었다. 생각보다 정말 간단했다(DB만 있으면 연결해주고 인스턴스 띄워주면 끝) 물론 이 친구도 단점이 존재하긴 했다. BigQuery에 직접 연결은 불가능

그리고 애정하는 ```BigQuery```에 대해 많은 공부를 하고 자료를 찾아봤다. 이 당시에 국내에 자료가 많지 않아.. NBT에 재직하시는 분에게 페이스북으로 질문을 꽤 했는데 정말 답변을 잘 해주셔서 큰 도움이 되었다!!!!(감사합니다 재광님)

## 5월 - 삽질, 삽질, SQL
이 기간엔 정말 많은 삽질을 했다. 데이터 분석을 위해서 이리저리... 
국가를 뛰어넘어 어떤 지역에서 앱을 많이 사용하는지 지도로 뿌려보고, 거기서 아이디어를 찾아 하나씩 파보고 그런 일을 했었다. 어떤 사람들이 앱을 사용하는가에 대해 많은 생각을 했던 시간.

동시에 BigQuery로 리텐션까지 뽑아내는 일까지 해야했다. 사실 GA를 쓰면 좋겠지만 하루에 사용하는 유저가 워낙 많아 비싸서.. 쿼리로 리텐션을 추출했다. 이 과정은 빅쿼리를 공부하기보다 SQL 기초부터 공부를 했다. 집합적인 관점에서 쿼리 짜는 방법을 계속 익혔다. 이 과정에서 ```R&D```를 담당하시는 분에게 많이 물어보고 배웠다. 쿼리로 할 수 있는 것들이 꽤 많아지게 된 시기

## 6월 - 데이터 이벤트 갈아엎기

데이터 이벤트에 대한 표준 규정이 없었다. 그리고 중복 이벤트도 있었고, 클라이언트 개발자분들도 부담스러워하는 로그 구조여서 갈아 엎었다. 이벤트 수를 대폭 줄이고, 파라미터도 정말 필요한 것만 남겨두었다

현재 구글에 계신 백정상님의 [슬라이드쉐어](https://www.slideshare.net/jeongsangbaek/ss-80795259)를 먼저 봤다면 더 잘했을텐데.. 라는 아쉬움도 있지만! 데이터 내부에 많은 변화가 있었다.

그리고 이 때 BigQuery를 더 많이 공부해서, 가공-가공-가공 파이프라인을 3단계까지 만들었다. 조금 더 데이터를 압축해서 필요한 것만 남겼다.

## 7월 - Tableau

4월에 만든 Superset의 대체재를 찾다가 유료지만 좋은 ```Tableau```를 사용해보자고 회사에 건의했다. 회사에서 결제해주셔서 사용하는데 정말 좋은 도구..!(단점은 유료)

위에서 쿼리로 작성했던 것을 시각화로 다 뿌려주고, BigQuery와 직접 연결해서 정말 좋았다. 여기서도 존재하는 단점은 1. BigQuery는 쿼리 비용이 나간다는 점(태블로에서 그래프를 그릴 때) 2. BigQuery와 Tableau의 연결이 엄청 빠릿빠릿하진 않다는 점. 그래서 지금도 다른 툴을 사용해야하나 고민중이다. 

단점이 있더라도 워낙 좋은 도구라 사용중(만약 웹에 직접 코딩하라고 했으면 못했을듯ㅋㅎ)

그리고 Google Cloud에서 진행하는 행사에 참여해 회사의 대표로 참석하게 되었다. 우리의 킹갓제네럴엠퍼럴 서버 개발자분이 구글 클라우드를 다 활용해 아키텍쳐를 아름답게 만드셔서 조대협님이 박수를 쳤는데, 그 효과로 나도 어깨가 으쓱-했다. 이 때 GCP를 사용하는 많은 분들을 만나 좋았다

## 8월 - 데이터 분석

위에서 보면 계속 데이터 엔지니어링에 초점이 맞춰있었다. 데이터 분석 직군인데 데이터를 쌓는 부분이 미약했기 때문에(그리고 이쪽이 재미있었다) 엔지니어링에 심취했었다. 이러면 안된다! 라는 생각으로 데이터 분석을 계속 했다. 데이터가 많아 샘플링을 해서 랜덤 포레스트에 던져보기도 하고, 노가다식으로 특정 이벤트를 토대로 리텐션을 다 계산해보고, 레포트 작성하고.. 
그 와중에 데이터 로그 설계도 하고, 데이터 QA, 요청 데이터 취합 등을 했다

이 시기에 내가 데이터 분석, 데이터 엔지니어링, 머신러닝(분석과 머신러닝이 겹치지만 이렇게 분류하고) 중 분석보단 엔지니어링, 머신러닝을 즐긴다는 것을 확실히 알게 되었다. 

그리고 [BigQuery 페이스북 그룹](https://www.facebook.com/groups/bigquery/)의 부운영자를 맡게 되었다. 

아, 졸업했다!(대졸자로 승격!)


## 9월 - Kaggle

진짜 8월까진 일에 심취했다. 다른 내용이 없ㅋ엉ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ
돌이켜보면 짧은 기간에 많은 것을 해봐서 개인의 성장이 폭풍!!!으로 되었던 시기였다

캐글뽀개기에서 진행하는 스터디에 참여했다. 돌이켜보면 이 때 정말 좋은 팀원분들을 만났고! 좋은 등수를 받고 있다(현재 Zillow 대회 62등/3778팀) 

캐글을 할 때 CPU 32 core, 200g ram, gpu 머신을 펑펑 사용해봤다..ㅎ(남은 크레딧 소진) Datalab에 대해서도 많이 알게 되었다

## 10월 - 살짝 번아웃

살짝 번아웃 증세가 나타났던 시기였다. 넓은 바다에서 길잃던 시기라고 해야하나, 조금 지쳤던 시기. 사실 내가 욕심이 많아 번아웃이 온 것이라 생각했다. 적절하게 일하며 적절하게 잘해야된다라고 다짐.

그래서 이 시기부터 칼퇴근을 시작했다. 회사에선 AB Test도 해보고 이것저것 조급해하지 않으며 여유롭게 보냈다

추석 연휴에 쉬는 날이 많아 [BigQuery Tutorial](https://github.com/zzsza/bigquery-tutorial)을 작성했다! Star는 43개인데 더 받고싶으면 따봉충인가 헤헷

<img src="https://github.com/zzsza/zzsza.github.io/blob/master/assets/img/meet.jpg?raw=true">

개발자 모임을 진행하며 다양한 시야를 갖게 되었다. 재밌었고 내가 행사 기획같은 것을 잘.. 하나..ㅎ 라는 생각도 들었다

## 11월 - CNN을 활용한 야한 사진검출, 비전 스터디

레트리카 앱의 소셜 부분에서 야한 사진을 올리는 외국인들이 참 많이 있었다. 기존에 구글 ```vision api```를 사용했지만 범용적이라 잘 맞추지 못했다. 오퍼레이션팀에서 손으로 직접 차단을 하는 것을 보고 안타까워서 혼자 진행해봤다. 대략 5일만에 만들어야 했다(..)

먼저 데이터 수집. 앱 내의 데이터는 터무니없이 적었고 크롤링하면 되지 뭐!!! 하고 시작했다. 그러나 ㅋㅋㅋㅋㅋㅋㅋㅋ 구글엔 야한 사진이 거의 없다. 있어도 너무 깨끗한 사진이다(실제 앱에서 나오는 사진은 배경도 있고, 어둡거나 그런데 구글의 사진들은 배경이 거의 다 단일색)
꾸역꾸역 찾아서 ```vgg16``` 로 만들어서 돌렸다.

그 결과 70%정도...... 분류......
하지만 데이터가 불균형하고 조금 잘못된 데이터도 있어서 사용하기엔 무리라고 생각했다.
검색해보니 NSFW Score라는 야후에서 공개된 모델이 있었다!
낼름 사용해서 적용했다. 데이터를 얼마나 넣었는지 궁금할정도로 남자 성기, 여자 가슴을 잘 잡는다. 심지어 자세까지 잡는다(..) ResNet을 사용해서 확실히 성능이 좋았다. 우리 데이터를 살짝 넣고 튜닝했다

이 시기에 야한 사진이 아닌 적나라한 사진을 너무 많이 봤다. 나는 괜찮은데 내 뒷자리에 계신 직원분들이 내 모니터를 보고 무슨 생각을 했을까..^^.. 

또한 비전 스터디를 시작하게 되었다. 갓엠퍼러짱짱인 우태강님과 함께 하는데, 같이 하는 상현님, 영택님도 열심히 해서! 정말 배울 것이 많은 스터디다. ```opencv```와 CNN류 알고리즘을 많이 알게 되는중. 이젠 ```GAN```을 학습할 예정

## 12월 - GCP 행사 주최, 보직 변경

12월엔 Google Cloud User Group에서 진행한 컨퍼런스에 집중했다. 발표를 준비할 시간이 없어 발표자로 지원하진 못했지만 나중엔 발표를 해야겠다! 라고 다짐.

온라인에서만 보던 GCP분들을 많이 보게 되었다. 물론 지식도 증가했다. 점점 GCP의 늪에 빠지게 되었다(애저도 써보고 싶은데 후후....)

그리고 회사에서 보직 변경을 제안 받았다. 
	```
	데이터 분석 -> 백엔드 엔지니어
	```

사실 백엔드라고 되어 있지만 레트리카의 서버는 Go로 이루어져 있고 주니어에게 맡길 생각이 전혀! 없을거란 것을 알고 있다. 내게 주어진 롤은 분산처리, 그리고 추천 엔진 만드는 일, 기타 딥러닝을 사용해 부가가치 생성하는 일- 정도라고 인지하고 있다

현재 이 일을 위해 ```Apache Beam```, ```Dataflow```를 공부하고 있다. Contributor에 도전하고 싶다

개발적 역량을 늘릴 수 있고, 기존엔 사수가 없이 진행하다보니 답답한 것들이 많았지만 지금은 배울 것이 있는분과 함께할 수 있어서 제안을 승낙했다.

12월 22일부터 18년 1월 1일까지 휴가-! 계속 공부만 하고 있다. 공부하고 써먹기 위한 방법을 생각하고 있다

그리고 리드미에서 멘토링을 계획하고 있다. 이제 많은 분들의 고민을 들어주고 싶다

# 2018년 계획

정말 가볍게 쓰려고 했는데 양이 이렇게나 많다. 이 글을 누가 읽을까..^^ 읽다가 중간에 이탈할 것 같다!!!

그래도 1년간 어떤 일이 있었는지 기록하는 것은 정말 중요하다 생각하기에 나에게 칭찬해주고 싶다

18년 계획은 아래와 같다

1. 블로그 글쓰기 모임 진행 : ```글또```라는 이름으로 지었다. 아마 1월부터 진행할 예정인데, 강제로 돈을 걷고 포스팅하면 돌려드리는 형식으로 진행할 예정이다. 그렇기 때문에 많은 인원을 내가 커버할 수가 없다. 아마 지인이나 소수로 운영하다 잘되면 크게 넓힐듯..!
2. 건강 챙기기 : 체력이 하락하고 살은 찌고 있다..^^.. 이제 운동을 하며 건강을 챙겨야겠다
3. 현재 하고있는 일에 대한 전문성 + 딥러닝쪽 특화
4. 캐글은 꾸준히 참여
5. 멘토링도 간간히 진행

뭐 가볍게 이렇게 적어두고 나중에 생각해야지!!!

<img src="https://github.com/zzsza/zzsza.github.io/blob/master/assets/img/github.png?raw=true">

아 그리고 어쩌다 보니 Github를 꾸준히 사용하는데, 그냥 공부한 것을 꾸준히 적다보니 이렇게 되었다. ```코딩->알게된 내용->기록``` 이런 루프였는데 계속 진행해야겠다-!! 

0년차 데이터 분석가지만 많은 성장을 이룬 2017년 고맙고 더 열심히 살아야지!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
